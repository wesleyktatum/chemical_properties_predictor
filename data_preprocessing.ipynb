{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../chemical_properties_predictor'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import models\n",
    "import data_utils as data\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To best prepare our datasets for training the VAE, there are some pre-processing steps and filtering that needs to occur. The objective of this notebook is to develop functions with the ChEMBL dataset that are applicable to any other dataset. The needed operations are:\n",
    "\n",
    "- tokenization\n",
    "- padding\n",
    "- creating a set (library) of unique tokens for individual datasets\n",
    "    - or curating a universal library from all available datasets\n",
    "- generating char_weights, which are a TFIDF-score\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (32,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Molecule ChEMBL ID',\n",
       " 'Molecule Name',\n",
       " 'Molecule Max Phase',\n",
       " 'Molecular Weight',\n",
       " '#RO5 Violations',\n",
       " 'AlogP',\n",
       " 'Compound Key',\n",
       " 'Smiles',\n",
       " 'Standard Type',\n",
       " 'Standard Relation',\n",
       " 'Standard Value',\n",
       " 'Standard Units',\n",
       " 'pChEMBL Value',\n",
       " 'Data Validity Comment',\n",
       " 'Comment',\n",
       " 'Uo Units',\n",
       " 'Ligand Efficiency BEI',\n",
       " 'Ligand Efficiency LE',\n",
       " 'Ligand Efficiency LLE',\n",
       " 'Ligand Efficiency SEI',\n",
       " 'Potential Duplicate',\n",
       " 'Assay ChEMBL ID',\n",
       " 'Assay Description',\n",
       " 'Assay Type',\n",
       " 'BAO Format ID',\n",
       " 'BAO Label',\n",
       " 'Assay Organism',\n",
       " 'Assay Tissue ChEMBL ID',\n",
       " 'Assay Tissue Name',\n",
       " 'Assay Cell Type',\n",
       " 'Assay Subcellular Fraction',\n",
       " 'Assay Parameters',\n",
       " 'Assay Variant Accession',\n",
       " 'Assay Variant Mutation',\n",
       " 'Target ChEMBL ID',\n",
       " 'Target Name',\n",
       " 'Target Organism',\n",
       " 'Target Type',\n",
       " 'Document ChEMBL ID',\n",
       " 'Source ID',\n",
       " 'Source Description',\n",
       " 'Document Journal',\n",
       " 'Document Year',\n",
       " 'Cell ChEMBL ID',\n",
       " 'Properties']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chembl_path = '../data/ChEMBL_subset.csv'\n",
    "# chembl_path = '../ChEMBL_subset.csv'\n",
    "\n",
    "df = pd.read_csv(chembl_path, delimiter = ';')\n",
    "col_names = df.columns.tolist()\n",
    "# df.head()\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247104, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O=c1oc(SCc2ccccc2)nc2ccccc12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc1c(O)c(=O)ccn1C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)c1cccc(C(C)C)c1OC(=O)[N-]S(=O)(=O)Oc1c(C(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN(O)C(=O)Cc1ccc(CC(=O)C2c3cccc(O)c3C(=O)c3c(O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nc1nc(=O)n([C@H]2CS[C@@H](CO)O2)cc1I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Smiles\n",
       "0                       O=c1oc(SCc2ccccc2)nc2ccccc12\n",
       "1                                  Cc1c(O)c(=O)ccn1C\n",
       "2  CC(C)c1cccc(C(C)C)c1OC(=O)[N-]S(=O)(=O)Oc1c(C(...\n",
       "3  CN(O)C(=O)Cc1ccc(CC(=O)C2c3cccc(O)c3C(=O)c3c(O...\n",
       "4               Nc1nc(=O)n([C@H]2CS[C@@H](CO)O2)cc1I"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop all rows with a nan in the 3 columns of interest\n",
    "mols_df = df[['Smiles']].replace('None', np.nan)\n",
    "mols_df = mols_df.dropna()\n",
    "mols_df = mols_df.astype({'Smiles':str})\n",
    "\n",
    "# #filter out molecules with SMILES strings longer than 250\n",
    "# mols_df = mols_df[mols_df.str.len() <= 250]\n",
    "\n",
    "# #Take every 10th sample to create toy dataset\n",
    "# print(mols_df.shape)\n",
    "# mols_df = mols_df.iloc[lambda x: x.index % 10 == 0]\n",
    "print(mols_df.shape)\n",
    "mols_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Supply CHAR_DICT",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8f9c7f372767>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'autoreload'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msmiles_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSmilesEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msmiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmols_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Smiles'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\python_projects\\github_repos\\ChemicalPropertiesPredictor\\chemical_properties_predictor\\data_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, CHAR_DICT, max_length, simple, one_hot)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;31m#             print(self.smiles2ind)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAR_DICT\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Supply CHAR_DICT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSmilesTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAR_DICT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Supply CHAR_DICT"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "smiles_encoder = data.SmilesEncoder()\n",
    "\n",
    "smiles = mols_df['Smiles'].tolist()\n",
    "\n",
    "tokenized_smiles = []\n",
    "\n",
    "for smi_str in tqdm(smiles, total = len(smiles)):\n",
    "#     smi_str = mols_df.iloc[i, 0]\n",
    "    padded = smiles_encoder.pad(smi_str, max_length = 250)\n",
    "    tokenized = smiles_encoder.tokenize(padded)\n",
    "    tokenized_smiles.append(tokenized)\n",
    "    \n",
    "print(tokenized_smiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e815c396014b88b29a8a4a023773ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=236902.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "183\n",
      "['*', '54', '97', '[S@+]', '91', '[C-]', '85', '[C@@]', '[14CH2]', '191', '[S@@]', '1', '431', '211', '19', 'I', '\\\\', '10', '543', '[N@+]', '[3H]', '26', '86', '[C@]', '7', '/', '68', '213', 'C', '[18O]', '[P@+]', '[I-]', '321', '36', '432', 'c', '[N@@+]', '18', '20', '[N+]', '[76Br]', '62', '.', '[o+]', '[11c]', '713', '72', 'S', 'Br', '42', '(', '231', '[17F]', '871', '[O+]', '[14C]', '2', '[35S]', '35', '[s+]', '75', '[127I]', '[14cH]', '56', '[131I]', '#', '6', '%', '25', 'Cl', '[Cl+3]', '[11CH3]', '34', '[S@]', '[P@@+]', '5', '69', '[14C@H]', '9', '312', '[P-]', '192', '123', '[124I]', '28', '57', '[PH]', '[76BrH]', '67', '[NH-]', '324', '61', '65', '21', ')', '341', '[NH3+]', '[11CH2]', '32', '[14CH]', '[123I]', '63', '[19F]', '[Na+]', '[14c]', '37', '24', '22', '[O-]', '78', '[CaH2]', '[N-]', '[14C@@H]', '8', '64', '53', '171', '[S+]', '[P+]', '41', '[14CH3]', '[Mg+2]', '162', '[n-]', '[Cl-]', 'O', '23', '[C@H]', '[OH-]', '[B-]', '46', '[125I]', '132', '[O]', '73', '[n+]', '[Br-]', '[18FH]', '4', '3', '175', '314', '27', '[32PH]', '=', 's', 'P', '16', '[11C]', '[Li+]', '[K+]', '43', '[2H]', '[Ca+2]', '412', '31', '12', '13', '[S@@+]', '-', 'F', '[S-]', '76', 'n', 'o', '87', '11', '52', '14', '[18F]', '[123IH]', '15', '[Zn+2]', 'N', '115', '17', '[P@]', '45', '51', '[C@@H]', '89', '[nH]', '[P@@]']\n"
     ]
    }
   ],
   "source": [
    "# print(tokenized_smiles[0])\n",
    "\n",
    "char_set = []\n",
    "\n",
    "for tokd in tqdm(tokenized_smiles, total = len(tokenized_smiles)):\n",
    "    tok_set = list(set(tokd))\n",
    "    char_set.extend(tok_set)\n",
    "    char_set = list(set(char_set))\n",
    "\n",
    "#need to ensure that the padding token is at index 0\n",
    "pad_idx = char_set.index('*')\n",
    "del char_set[pad_idx]\n",
    "char_set.insert(0, '*')\n",
    "\n",
    "print(len(char_set))\n",
    "print(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "char_dict = {}\n",
    "for i in range(len(char_set)):\n",
    "    char_dict[char_set[i]] = i\n",
    "    \n",
    "print(len(char_dict))\n",
    "\n",
    "char_params = {\n",
    "    'MAX_LENGTH': 250,\n",
    "    'CHAR_DICT': char_dict,\n",
    "    'NUM_CHAR': len(char_set)\n",
    "}\n",
    "\n",
    "char_weights = smiles_encoder.get_char_weights(tokenized_smiles, char_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.88435443, 1.        , 1.        ,\n",
       "       1.        , 0.65874936, 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.91909856, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.86885986, 1.        ,\n",
       "       0.80395201, 1.        , 1.        , 0.60633794, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.59377694, 1.        , 1.        , 1.        , 0.94020025,\n",
       "       1.        , 1.        , 0.89833955, 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.8142734 , 0.96210695, 1.        ,\n",
       "       0.625921  , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.67163758, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.90062842, 0.97570592, 1.        , 1.        , 0.79492957,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.84680727, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.9244669 , 0.625921  ,\n",
       "       1.        , 1.        , 1.        , 0.98951492, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.92391561, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.64853423, 0.93732827, 0.74338902, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.76222076, 0.70315967,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.67476898,\n",
       "       0.87767364, 0.99297344, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.87074928, 1.        , 1.        , 0.77497288,\n",
       "       0.74554808, 1.        , 1.        , 0.69728651, 0.88305617,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.68241408, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.75009637,\n",
       "       1.        , 0.83674511, 1.        ])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#save char_dict, char_weights for loading into model\n",
    "\n",
    "with open('../data/CHAR_DICT.json', 'w') as f:\n",
    "    json.dump(char_dict, f)\n",
    "    f.close()\n",
    "    \n",
    "np.save('../data/CHAR_WEIGHTS.pickle', char_weights, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'B'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-aa36fda75def>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchar_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'B'"
     ]
    }
   ],
   "source": [
    "char_dict['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ELEMENT_SYMBOLS = [#uncommon atoms that can be construed as two atoms (e.g. CS, NO) are excluded\n",
    "    'Ac', 'Ag', 'Al', 'Am', 'Ar', 'As', 'At', 'Au', 'Ba', 'Be', 'Bh', 'Bi', 'Bk', 'Br', 'B', 'Ca', 'Cd', 'Ce',\n",
    "    'Cl', 'Cm', 'Cr', 'Cu', 'C', 'Db', 'Ds', 'Dy', 'Er', 'Es', 'Eu', 'Fe', 'Fl', 'Fm', 'Fr', 'F', 'Ga', 'Gd',\n",
    "    'Ge', 'He', 'Hg', 'H', 'In', 'Ir', 'I', 'Kr', 'K', 'La', 'Li', 'Lr', 'Lu', 'Lv', 'Md', 'Mg', 'Mn', 'Mo',\n",
    "    'Mt', 'Na', 'Nb', 'Nd', 'Ne', 'Ni', 'N', 'O', 'Pa', 'Pb', 'Pd', 'Pm', 'Po', 'Pr', 'Pt', 'Pu', 'P', 'Ra',\n",
    "    'Rb', 'Re', 'Rf', 'Rg', 'Rh', 'Rn', 'Ru', 'Sb', 'Se', 'Sg', 'Si', 'Sm', 'Sr', 'S', 'Ta', 'Tb', 'Tc', 'Te',\n",
    "    'Th', 'Ti', 'Tl', 'Tm', 'Uuo', 'Uup', 'Uus', 'Uut', 'U', 'V', 'W', 'Xe', 'Yb', 'Y', 'Zn', 'Zr'\n",
    "    ]\n",
    "\n",
    "BRACKET_SYMBOLS = [\n",
    "    '\\(', '\\)', '\\[', '\\]', '\\{', '\\}'\n",
    "]\n",
    "\n",
    "NUMBERS = '(\\d{3}|\\d{2}|\\d{1})'\n",
    "\n",
    "SMILES_SYMBOLS = [\n",
    "    '\\.', '=', '#', '-', '\\+', '\\+', '\\\\\\\\', '\\/', '_', ':', '~', '@@', '@@', '@', '@', '\\?', '>', '\\*', '\\$', '\\%'\n",
    "]\n",
    "\n",
    "element_re = re.compile('|'.join(ELEMENT_SYMBOLS), flags = re.I)\n",
    "number_re = re.compile(NUMBERS)\n",
    "smiles_re = re.compile('|'.join(SMILES_SYMBOLS))\n",
    "bracket_re = re.compile('|'.join(BRACKET_SYMBOLS))\n",
    "\n",
    "def match_brackets(string):\n",
    "    matches = []\n",
    "    for m in bracket_re.finditer(string):\n",
    "        match_span = (m.start(), m.group())\n",
    "        matches.append(match_span)\n",
    "    return matches\n",
    "    \n",
    "def match_atoms(string):\n",
    "    matches = []\n",
    "    for m in element_re.finditer(string):\n",
    "        match_span = (m.start(), m.group())\n",
    "        matches.append(match_span)\n",
    "    return matches\n",
    "\n",
    "def match_smiles_symbols(string):\n",
    "    matches = []\n",
    "    for m in smiles_re.finditer(string):\n",
    "        match_span = (m.start(), m.group())\n",
    "        matches.append(match_span)\n",
    "    return matches\n",
    "\n",
    "def match_numbers(string):\n",
    "    matches = []\n",
    "    for m in number_re.finditer(string):\n",
    "        match_span = (m.start(), m.group())\n",
    "        matches.append(match_span)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of smiles string is: \t 36\n",
      "[(5, '('), (8, ')'), (10, '('), (11, '['), (15, ']'), (19, '['), (24, ']'), (25, '('), (28, ')'), (31, ')')] \n",
      "\t 10\n",
      "[(0, 'N'), (1, 'c'), (3, 'n'), (4, 'c'), (7, 'O'), (9, 'n'), (12, 'C'), (14, 'H'), (17, 'C'), (18, 'S'), (20, 'C'), (23, 'H'), (26, 'C'), (27, 'O'), (29, 'O'), (32, 'c'), (33, 'c'), (35, 'I')] \n",
      "\t 18\n",
      "[(6, '='), (13, '@'), (21, '@@')] \n",
      "\t 3\n",
      "[(2, '1'), (16, '2'), (30, '2'), (34, '1')] \n",
      "\t 4\n"
     ]
    }
   ],
   "source": [
    "test_smiles = 'Nc1nc(=O)n([C@H]2CS[C@@H](CO)O2)cc1I'\n",
    "print('Length of smiles string is: \\t', len(test_smiles))\n",
    "\n",
    "brackets = match_brackets(test_smiles)\n",
    "atoms = match_atoms(test_smiles)\n",
    "symbols = match_smiles_symbols(test_smiles)\n",
    "numbers = match_numbers(test_smiles)\n",
    "\n",
    "print(brackets, '\\n\\t', len(brackets))\n",
    "print(atoms, '\\n\\t', len(atoms))\n",
    "print(symbols, '\\n\\t', len(symbols))\n",
    "print(numbers, '\\n\\t', len(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reconstruct_smiles_from_re(original, brackets, atoms, symbols, numbers):\n",
    "    smiles_len = len(original)\n",
    "    reconstructed = ''\n",
    "    \n",
    "    for i in range(smiles_len):\n",
    "        reconstructed += 'z'\n",
    "        \n",
    "    for br in brackets:\n",
    "        ind = br[0]\n",
    "        tok = br[1]\n",
    "        if len(tok) > 1:\n",
    "            tok_num = len(tok)\n",
    "        else:\n",
    "            tok_num = 1\n",
    "        for i in range(tok_num):\n",
    "            reconstructed = reconstructed[:ind+i] + tok[i]  + reconstructed[ind+i+1:]\n",
    "                \n",
    "    for at in atoms:\n",
    "        ind = at[0]\n",
    "        tok = at[1]\n",
    "        if len(tok) > 1:\n",
    "            tok_num = len(tok)\n",
    "        else:\n",
    "            tok_num = 1\n",
    "        for i in range(tok_num):\n",
    "            reconstructed = reconstructed[:ind+i] + tok[i]  + reconstructed[ind+i+1:]\n",
    "            \n",
    "    for sy in symbols:\n",
    "        ind = sy[0]\n",
    "        tok = sy[1]\n",
    "        if len(tok) > 1:\n",
    "            tok_num = len(tok)\n",
    "        else:\n",
    "            tok_num = 1\n",
    "        for i in range(tok_num):\n",
    "            reconstructed = reconstructed[:ind+i] + tok[i]  + reconstructed[ind+i+1:]\n",
    "            \n",
    "    for num in numbers:\n",
    "        ind = num[0]\n",
    "        tok = num[1]\n",
    "        if len(tok) > 1:\n",
    "            tok_num = len(tok)\n",
    "        else:\n",
    "            tok_num = 1\n",
    "        for i in range(tok_num):\n",
    "            reconstructed = reconstructed[:ind+i] + tok[i]  + reconstructed[ind+i+1:]\n",
    "                \n",
    "    assert len(reconstructed) == len(original), ('smiles error: length mismatch between original and reconstructed')\n",
    "            \n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nc1nc(=O)n([C@H]2CS[C@@H](CO)O2)cc1I\n",
      "Nc1nc(=O)n([C@H]2CS[C@@H](CO)O2)cc1I\n"
     ]
    }
   ],
   "source": [
    "rec = reconstruct_smiles_from_re(test_smiles, brackets, atoms, symbols, numbers)\n",
    "print(test_smiles)\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def spans_to_index_list(char_dict, brackets, atoms, symbols, numbers):\n",
    "    spans = brackets + atoms + symbols + numbers\n",
    "    \n",
    "    sorted_spans = sorted(spans, key = lambda spn: spn[0])\n",
    "    print(sorted_spans)\n",
    "    \n",
    "    token_list = []\n",
    "    for span in sorted_spans:\n",
    "        tok = span[1]\n",
    "        ind = char_dict[tok]\n",
    "        token_list.append(ind)\n",
    "        \n",
    "    return token_list\n",
    "\n",
    "\n",
    "def build_char_dict(smiles_strings):\n",
    "    char_dict = {}\n",
    "    char_set = []\n",
    "    for smiles in tqdm(smiles_strings, total = len(smiles_strings)):\n",
    "        brackets = match_brackets(smiles)\n",
    "        atoms = match_atoms(smiles)\n",
    "        symbols = match_smiles_symbols(smiles)\n",
    "        numbers = match_numbers(smiles)\n",
    "        \n",
    "        span_list = brackets+atoms+symbols+numbers\n",
    "        span_list = [tup[1] for tup in span_list]\n",
    "        span_set = list(set(span_list))\n",
    "        \n",
    "        char_set.extend(span_set)\n",
    "        char_set = list(set(char_set))\n",
    "        char_set.sort()\n",
    "        \n",
    "    try:\n",
    "        #need to ensure that the padding token is at index 0\n",
    "        pad_idx = char_set.index('*')\n",
    "        del char_set[pad_idx]\n",
    "        char_set.insert(0, '*')\n",
    "    except:\n",
    "        char_set.insert(0, '*')\n",
    "        \n",
    "    for i, char in enumerate(char_set):\n",
    "        char_dict[char] = i\n",
    "        \n",
    "    return char_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3b158ee0bb4c91be06b86b44b0c286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=247104.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "smiles = mols_df['Smiles'].tolist()\n",
    "\n",
    "tokenizer = data.SmilesTokenizer(char_dict = None)\n",
    "\n",
    "char_dict = tokenizer.build_char_dict(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'*': 0,\n",
       " '#': 1,\n",
       " '%': 2,\n",
       " '(': 3,\n",
       " ')': 4,\n",
       " '+': 5,\n",
       " '-': 6,\n",
       " '.': 7,\n",
       " '/': 8,\n",
       " '1': 9,\n",
       " '10': 10,\n",
       " '102': 11,\n",
       " '109': 12,\n",
       " '11': 13,\n",
       " '115': 14,\n",
       " '12': 15,\n",
       " '123': 16,\n",
       " '124': 17,\n",
       " '125': 18,\n",
       " '127': 19,\n",
       " '13': 20,\n",
       " '131': 21,\n",
       " '132': 22,\n",
       " '14': 23,\n",
       " '15': 24,\n",
       " '16': 25,\n",
       " '162': 26,\n",
       " '17': 27,\n",
       " '171': 28,\n",
       " '175': 29,\n",
       " '18': 30,\n",
       " '19': 31,\n",
       " '191': 32,\n",
       " '192': 33,\n",
       " '2': 34,\n",
       " '20': 35,\n",
       " '21': 36,\n",
       " '211': 37,\n",
       " '213': 38,\n",
       " '22': 39,\n",
       " '23': 40,\n",
       " '231': 41,\n",
       " '24': 42,\n",
       " '245': 43,\n",
       " '25': 44,\n",
       " '26': 45,\n",
       " '27': 46,\n",
       " '28': 47,\n",
       " '3': 48,\n",
       " '31': 49,\n",
       " '312': 50,\n",
       " '314': 51,\n",
       " '32': 52,\n",
       " '321': 53,\n",
       " '324': 54,\n",
       " '34': 55,\n",
       " '341': 56,\n",
       " '35': 57,\n",
       " '36': 58,\n",
       " '37': 59,\n",
       " '4': 60,\n",
       " '41': 61,\n",
       " '412': 62,\n",
       " '42': 63,\n",
       " '43': 64,\n",
       " '431': 65,\n",
       " '432': 66,\n",
       " '45': 67,\n",
       " '46': 68,\n",
       " '5': 69,\n",
       " '51': 70,\n",
       " '52': 71,\n",
       " '53': 72,\n",
       " '54': 73,\n",
       " '543': 74,\n",
       " '56': 75,\n",
       " '57': 76,\n",
       " '58': 77,\n",
       " '6': 78,\n",
       " '61': 79,\n",
       " '62': 80,\n",
       " '63': 81,\n",
       " '64': 82,\n",
       " '642': 83,\n",
       " '65': 84,\n",
       " '67': 85,\n",
       " '68': 86,\n",
       " '69': 87,\n",
       " '7': 88,\n",
       " '713': 89,\n",
       " '72': 90,\n",
       " '73': 91,\n",
       " '74': 92,\n",
       " '75': 93,\n",
       " '76': 94,\n",
       " '78': 95,\n",
       " '8': 96,\n",
       " '824': 97,\n",
       " '85': 98,\n",
       " '86': 99,\n",
       " '87': 100,\n",
       " '871': 101,\n",
       " '89': 102,\n",
       " '9': 103,\n",
       " '91': 104,\n",
       " '97': 105,\n",
       " '98': 106,\n",
       " '=': 107,\n",
       " '@': 108,\n",
       " '@@': 109,\n",
       " 'Ag': 110,\n",
       " 'Al': 111,\n",
       " 'As': 112,\n",
       " 'B': 113,\n",
       " 'BH': 114,\n",
       " 'Br': 115,\n",
       " 'C': 116,\n",
       " 'Ca': 117,\n",
       " 'Cl': 118,\n",
       " 'F': 119,\n",
       " 'H': 120,\n",
       " 'He': 121,\n",
       " 'I': 122,\n",
       " 'K': 123,\n",
       " 'Li': 124,\n",
       " 'Mg': 125,\n",
       " 'N': 126,\n",
       " 'Na': 127,\n",
       " 'O': 128,\n",
       " 'P': 129,\n",
       " 'S': 130,\n",
       " 'Se': 131,\n",
       " 'Si': 132,\n",
       " 'Te': 133,\n",
       " 'Zn': 134,\n",
       " '[': 135,\n",
       " '\\\\': 136,\n",
       " ']': 137,\n",
       " 'c': 138,\n",
       " 'n': 139,\n",
       " 'o': 140,\n",
       " 's': 141,\n",
       " 'se': 142,\n",
       " 'te': 143}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/CHAR_DICT.json', 'w') as f:\n",
    "    json.dump(char_dict, f)\n",
    "    f.close()\n",
    "\n",
    "char_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cc1973c1a64be89fe5fdc9d454a604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=247104.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "char_params = {\n",
    "    'MAX_LENGTH': 250,\n",
    "    'CHAR_DICT': char_dict,\n",
    "    'NUM_CHAR': len(char_dict)\n",
    "}\n",
    "\n",
    "tokenizer = data.SmilesTokenizer(char_dict = char_dict)\n",
    "tokenized_smiles = []\n",
    "for smi in tqdm(smiles, total = len(smiles)):\n",
    "#     print(smi)\n",
    "    tokenized, index_list = tokenizer.tokenize(smi)\n",
    "#     print(tokenized)\n",
    "    tokenized_smiles.append(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', '=', 'c', '1', 'o', 'c', '(', 'S', 'C', 'c', '2', 'c', 'c', 'c', 'c', 'c', '2', ')', 'n', 'c', '2', 'c', 'c', 'c', 'c', 'c', '12']\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "print(tokenized_smiles[0])\n",
    "\n",
    "smiles_encoder = data.SmilesEncoder(CHAR_DICT = char_dict)\n",
    "char_weights = smiles_encoder.get_char_weights(tokenized_smiles, char_params)\n",
    "\n",
    "np.save('../data/CHAR_WEIGHTS.pickle', char_weights, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.90045848, 1.        , 0.61895721, 0.61895721,\n",
       "       0.89009346, 0.76104495, 0.89135292, 0.80079304, 0.65662237,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.86297838, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.66937234,\n",
       "       1.        , 0.92211497, 1.        , 1.        , 1.        ,\n",
       "       0.93319289, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.70068396, 1.        ,\n",
       "       1.        , 1.        , 0.98461713, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.75799074, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.83570046,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.94577592, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.6641944 , 0.71647088, 0.72201138,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.95190052, 0.5935924 , 1.        , 0.79305938, 0.74310326,\n",
       "       0.68115978, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.66782344, 1.        , 0.63974218, 0.95785238,\n",
       "       0.80534816, 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.67020676, 0.91597534, 0.67020676, 0.59223121, 0.68917665,\n",
       "       0.88200646, 0.87596064, 1.        , 1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
